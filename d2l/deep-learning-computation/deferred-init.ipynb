{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fundebug/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "net =nn.Sequential(nn.LazyLinear(256),nn.ReLU(),nn.LazyLinear(10))\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[OrderedDict([('weight', <UninitializedParameter>),\n              ('bias', <UninitializedParameter>)]),\n OrderedDict(),\n OrderedDict([('weight', <UninitializedParameter>),\n              ('bias', <UninitializedParameter>)])]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[net[i].state_dict() for i in range(len(net))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "X=torch.rand(2,20)\n",
    "net(X)\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low=torch.finfo(torch.float32).min/10\n",
    "high=torch.finfo(torch.float32).max/10\n",
    "X=torch.zeros([2,20],dtype=torch.float32)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.9365e+37,  2.7204e+37,  2.9709e+37, -2.3483e+37, -1.7261e+37,\n         -3.1236e+37,  2.0089e+37,  1.5402e+37, -1.3624e+36, -1.3939e+37,\n         -9.8681e+36,  1.0002e+36,  8.4974e+36, -1.1041e+37, -2.4709e+37,\n         -3.3733e+37, -3.1517e+37, -2.4776e+37, -2.1717e+37, -3.0020e+37],\n        [-2.5535e+37, -2.9962e+37,  8.0498e+36, -1.1151e+37, -2.3256e+37,\n          6.2482e+36,  2.7948e+37, -1.3065e+37,  6.8291e+36,  7.6842e+36,\n         -1.4182e+37,  1.0021e+37,  6.6997e+36,  2.1964e+37, -1.4098e+37,\n          1.4806e+36, -1.2458e+37, -1.1126e+37, -1.8587e+37,  7.8846e+36]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.uniform_(low,high)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net(X)\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('mps')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu计算总时长: 41.53 ms\n",
      "gpu计算总时长: 12.58 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime1=time.time()\n",
    "for i in range(100):\n",
    "    A = torch.ones(500,500)\n",
    "    B = torch.ones(500,500)\n",
    "    C = torch.matmul(A,B)\n",
    "endTime1=time.time()\n",
    "\n",
    "startTime2=time.time()\n",
    "for i in range(100):\n",
    "    A = torch.ones(500,500,device=torch.device('mps'))\n",
    "    B = torch.ones(500,500,device=torch.device('mps'))\n",
    "    C = torch.matmul(A,B)\n",
    "endTime2=time.time()\n",
    "print('cpu计算总时长:', round((endTime1 - startTime1)*1000, 2),'ms')\n",
    "print('gpu计算总时长:', round((endTime2 - startTime2)*1000, 2),'ms')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
