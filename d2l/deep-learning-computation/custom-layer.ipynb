{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,X):\n",
    "        return X-X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-2., -1.,  0.,  1.,  2.])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=CenteredLayer()\n",
    "layer(torch.FloatTensor([1,2,3,4,5]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "net=nn.Sequential(nn.Linear(8,128),CenteredLayer())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.8626e-09, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=net(torch.rand(4,8))\n",
    "Y.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.4305, -0.0945, -1.0421, -0.3269, -0.0279,  0.0058,  0.0206,  0.0062,\n         -0.2447, -0.2474, -0.4054,  0.0998,  0.4953, -0.1241,  0.1289,  0.1513,\n          0.2808,  0.2062, -0.3624, -0.4039,  0.4179,  0.1977, -0.6156,  0.3260,\n         -0.0644, -0.6498,  0.1237,  0.0385,  0.4761,  0.0480, -0.0660, -0.0574,\n         -0.3517, -0.1384, -0.2353, -0.0578,  0.4460, -0.4074, -0.4140,  0.3519,\n         -0.2214, -0.2542,  0.4210, -0.4492, -0.1488, -0.2534, -0.3539,  0.0523,\n         -0.4966,  0.2610, -0.0351, -0.5337,  0.4671,  0.7397, -0.1587,  0.4632,\n          0.4403, -0.4799, -0.0516, -0.2882,  0.9108, -0.0018, -0.0607,  0.2936,\n          0.0493, -0.0260, -0.1070, -0.1803,  0.6373, -0.3384,  0.0580, -0.0663,\n         -0.1225, -0.0071,  0.2520, -0.4735,  0.0177, -0.2605,  0.8785,  0.7435,\n          0.0741, -0.1576, -0.3716, -0.3481,  0.0078,  0.2151,  0.4091, -0.7329,\n         -0.0607,  0.3838,  0.0538,  0.5179, -0.0804,  0.1078, -0.2648,  0.6417,\n         -0.2970, -0.0687,  0.3290,  0.0151,  0.1624,  0.2044,  0.5599,  0.0532,\n          0.3640, -0.0942,  0.6894,  0.6071, -0.0779, -0.8152,  0.1896,  0.0226,\n          0.3129, -0.0113, -0.2627, -0.1113,  0.2729, -0.0143,  0.0588,  0.5352,\n          0.0899,  0.1764, -0.4224, -0.2013, -1.1704,  0.1214, -0.2335, -0.0790],\n        [-0.1343, -0.2908, -0.7880, -0.3954,  0.1764, -0.4084, -0.1810,  0.2672,\n         -0.6894,  0.3666, -0.4756,  0.3299,  0.6038, -0.1898, -0.0392,  0.2775,\n          0.1964, -0.2176, -0.4171, -0.1868, -0.1968,  0.0191, -0.3933,  0.1969,\n         -0.1389, -0.8094, -0.2267, -0.2472,  0.7432,  0.0386, -0.0223, -0.2682,\n         -0.0793, -0.1091, -0.2117, -0.1352,  0.4596, -0.4188, -0.4032,  0.1554,\n         -0.2202, -0.1763,  0.3828, -0.3056,  0.2230, -0.0812, -0.0274, -0.1080,\n         -0.1504,  0.0532, -0.3932, -0.6965, -0.0168,  0.5837,  0.1706,  0.5068,\n          0.4195, -0.3192,  0.2824, -0.3636,  0.6836,  0.0457,  0.2676, -0.1572,\n          0.4621,  0.2316,  0.0294, -0.4844,  0.6554, -0.4856,  0.1211, -0.1826,\n          0.1385, -0.0133,  0.5857, -0.0402, -0.2779, -0.1783,  0.5559,  1.1359,\n         -0.2607,  0.0306, -0.2519, -0.2587,  0.2646, -0.0443,  0.3842, -0.2914,\n          0.1684,  0.4922, -0.0911,  0.0405,  0.2763,  0.0709, -0.0763,  0.3616,\n         -0.4620,  0.3275,  0.3521, -0.0303, -0.1650,  0.1951,  0.6242, -0.1090,\n          0.2738, -0.4378,  0.6363,  0.4454, -0.1489, -0.7513, -0.2498, -0.0791,\n         -0.1843,  0.3751, -0.6382, -0.3660, -0.1477,  0.1342, -0.1034,  0.1454,\n          0.0808,  0.3235, -0.2818, -0.3103, -0.9591, -0.1716,  0.2571, -0.1298],\n        [-0.0978, -0.1633, -1.0641, -0.1285, -0.0069,  0.0284,  0.2641,  0.4151,\n         -0.1461, -0.2911, -0.5292, -0.0129,  1.0162, -0.1030,  0.3125, -0.0329,\n          0.0194, -0.1809, -0.1487, -0.1211,  0.4394, -0.0278, -0.5288,  0.6863,\n         -0.2275, -1.0541,  0.3528,  0.0405,  0.4355,  0.2355, -0.0825,  0.1433,\n         -0.2719, -0.0800, -0.6074, -0.3406,  0.2152, -0.4317, -1.0296, -0.1102,\n         -0.3093, -0.1329,  0.9645, -0.3767,  0.3275, -0.2044, -0.1801,  0.2497,\n         -0.5407,  0.0039,  0.3977, -0.3657,  0.9841,  0.9240,  0.0926,  0.2981,\n          0.5851, -0.1614,  0.1170, -0.2810,  0.6778, -0.0210, -0.2675,  0.4090,\n         -0.0114,  0.4085,  0.0358, -0.5783,  1.1820, -0.8748,  0.3183,  0.4475,\n          0.2348, -0.0449,  0.3617, -0.3027, -0.0014, -0.2870,  1.0427,  0.6495,\n         -0.0761, -0.4337, -0.0603,  0.0747,  0.0168,  0.1031,  0.0530, -0.4393,\n          0.3621, -0.0162,  0.3484,  0.0830,  0.3953, -0.0647, -0.7043,  0.4163,\n         -0.7494,  0.0511,  0.2746,  0.0564,  0.1922,  1.1198,  0.3897, -0.0636,\n          0.5967, -0.4434,  0.8843,  0.3934,  0.0655, -0.7869,  0.4149,  0.4717,\n          0.2073, -0.6194,  0.0322,  0.0761, -0.1168,  0.2901, -0.3057,  0.5265,\n          0.0220,  0.3712,  0.1614, -0.2663, -1.2891,  0.1049,  0.0161, -0.0218],\n        [-0.4976, -0.1538, -1.3286, -0.2870, -0.1192, -0.1009,  0.1297, -0.0983,\n         -0.2500,  0.0211, -0.4934,  0.2794,  0.7342, -0.1457, -0.0468,  0.2415,\n          0.2024,  0.1674, -0.2663, -0.5485,  0.3494,  0.0832, -0.7223,  0.2046,\n         -0.1221, -0.6136,  0.1566, -0.1156,  0.6695,  0.1480, -0.1192, -0.2580,\n         -0.4185, -0.0640, -0.2129, -0.0839,  0.7397, -0.7128, -0.4687,  0.5994,\n         -0.2871, -0.3757,  0.2366, -0.3912, -0.3772, -0.4725, -0.6037,  0.0405,\n         -0.5962,  0.3608, -0.1543, -0.6217,  0.4481,  0.7655, -0.4175,  0.5660,\n          0.5265, -0.6796, -0.0957, -0.5959,  1.2168,  0.0449,  0.1288,  0.2265,\n         -0.1012, -0.2970, -0.2318, -0.0740,  0.5439, -0.0883, -0.0275, -0.0817,\n         -0.4673,  0.0797,  0.3958, -0.3901, -0.0767, -0.4488,  0.7460,  0.9425,\n         -0.0158,  0.1342, -0.6404, -0.3426,  0.0941,  0.2905,  0.5341, -0.6809,\n         -0.0802,  0.8168,  0.0267,  0.8957, -0.1135,  0.3161, -0.0775,  0.8763,\n         -0.3900,  0.0627,  0.6234, -0.0895, -0.0439,  0.1639,  0.6438,  0.0490,\n          0.2656, -0.1962,  0.6281,  0.5332, -0.1251, -0.8750,  0.2578, -0.1834,\n          0.2900,  0.2456, -0.3953, -0.4833,  0.3194, -0.2118,  0.1159,  0.3916,\n         -0.0533,  0.4845, -0.5046, -0.4142, -1.1905,  0.0669, -0.0540,  0.0276]],\n       grad_fn=<SubBackward0>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,in_units,units):\n",
    "        super().__init__()\n",
    "        self.weight=nn.Parameter(torch.randn(in_units,units))\n",
    "        self.bias=nn.Parameter(torch.randn(units,))\n",
    "    def forward(self,X):\n",
    "        linear=torch.matmul(X,self.weight.data)+self.bias.data\n",
    "        return F.relu(linear)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[ 0.0915, -0.4435,  0.4483],\n        [-0.5112,  0.4358, -0.7842],\n        [ 1.5728,  0.5046, -0.9550],\n        [ 0.8024,  2.5126, -0.0369],\n        [-0.6394, -0.6200,  0.2133]], requires_grad=True)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear=MyLinear(5,3)\n",
    "linear.weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.9965, 1.3945, 0.0000],\n        [2.5638, 1.9842, 0.0000]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2,5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.4463],\n        [0.5934]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Sequential(MyLinear(64,8),MyLinear(8,1))\n",
    "net(torch.rand(2,64))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
